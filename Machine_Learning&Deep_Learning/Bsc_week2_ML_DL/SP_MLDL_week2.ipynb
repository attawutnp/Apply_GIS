{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\t\n",
    "87613259\tScripting Language\n",
    "=======================================\n",
    "Credit : Patrick Gray (patrick.c.gray at duke) - https://github.com/patrickcgray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn\n",
    "\n",
    "In this chapter we will be using the Naive Bayes implementation provided by the [scikit-learn](http://scikit-learn.org) library. `scikit-learn` is an amazing machine learning library that provides easy and consistent interfaces to many of the most popular machine learning algorithms. It is built on top of the pre-existing scientific Python libraries, including `numpy`, `scipy`, and `matplotlib`, which makes it very easy to incorporate into your workflow. The number of available methods for accomplishing any task contained within the library is (in my opinion) its real strength. No single algorithm is best for all tasks under all circumstances, and `scikit-learn` helps you understand this by abstracting the details of each algorithm to simple consistent interfaces. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png\" alt=\"An Iris\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This figure](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) shows the classification predictions and the decision surfaces produced for three classification problems using 9 different classifiers. What is even more impressive is that all of this took only about 110 lines of code, including comments!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "#### Opening the images\n",
    "Our first step is to recall our previous chapter's lessons and import the things we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to collect all the Sentinal-2 bands because they come as individual images one per band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # we need os to do some basic file operations\n",
    "\n",
    "sentinal_fp = \"sentinel-2/\"\n",
    "# find every file in the sentinal_fp directory\n",
    "sentinal_band_paths = [os.path.join(sentinal_fp, f) for f in os.listdir(sentinal_fp) if os.path.isfile(os.path.join(sentinal_fp, f))]\n",
    "sentinal_band_paths.sort()\n",
    "sentinal_band_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a rasterio dataset object containing all bands in order to use the mask() function and extract pixel values using geospatial polygons.\n",
    "\n",
    "We'll do this by creating a new raster dataset and saving it for future uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a products directory within the data dir which won't be uploaded to Github\n",
    "img_dir = 'products/'\n",
    "\n",
    "# check to see if the dir it exists, if not, create it\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "\n",
    "# filepath for image we're writing out\n",
    "img_fp = img_dir + 'sentinel_bands.tif'\n",
    "\n",
    "# Read metadata of first file and assume all other bands are the same\n",
    "with rasterio.open(sentinal_band_paths[0]) as src0:\n",
    "    meta = src0.meta\n",
    "\n",
    "# Update metadata to reflect the number of layers\n",
    "meta.update(count = len(sentinal_band_paths))\n",
    "\n",
    "# Read each layer and write it to stack\n",
    "with rasterio.open(img_fp, 'w', **meta) as dst:\n",
    "    for id, layer in enumerate(sentinal_band_paths, start=1):\n",
    "        with rasterio.open(layer) as src1:\n",
    "            dst.write_band(id, src1.read(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay we've successfully written it out now let's open it back up and make sure it meets our expectations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = rasterio.open(img_fp)\n",
    "img_rows, img_cols = full_dataset.shape\n",
    "img_bands = full_dataset.count\n",
    "print(full_dataset.shape) # dimensions\n",
    "print(full_dataset.count) # bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clip the image and take a look where we know the training data was from the last lesson (on the NC Rachel Carson Reserve) just to make sure it looks normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import show\n",
    "\n",
    "clipped_img = full_dataset.read([4,3,2])[:, 150:600, 250:1400]\n",
    "print(clipped_img.shape)\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "show(clipped_img[:, :, :], ax=ax, transform=full_dataset.transform) # add the transform arg to get it in lat long coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay looks good! Our raster dataset is ready!\n",
    "\n",
    "### Now our goal is to get the pixels from the raster as outlined in each shapefile. \n",
    "\n",
    "Our training data, the shapefile we've worked with, contains one main field we care about:\n",
    "+ a Classname field (String datatype)\n",
    "\n",
    "Combined with the innate location information of polygons in a Shapefile, we have all that we need to use for pairing labels with the information in our raster.\n",
    "\n",
    "However, in order to pair up our vector data with our raster pixels, we will need a way of co-aligning the datasets in space. \n",
    "\n",
    "We'll do this using the rasterio mask function which takes in a dataset and a polygon and then outputs a numpy array with the pixels in the polygon.\n",
    "\n",
    "Let's run through an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open up our shapefile and check its crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = gpd.read_file('training_data//rcr_landcover.shp')\n",
    "shapefile.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the projections don't match! Let's use some geopandas magic to reproject all our shapefiles to lat, long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = shapefile.to_crs({'init': 'epsg:4326'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shapefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to extract the geometry of each feature in the shapefile in GeoJSON format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this generates a list of shapely geometries\n",
    "geoms = shapefile.geometry.values \n",
    "\n",
    "# let's grab a single shapely geometry to check\n",
    "geometry = geoms[0] \n",
    "print(type(geometry))\n",
    "print(geometry)\n",
    "\n",
    "# transform to GeoJSON format\n",
    "from shapely.geometry import mapping\n",
    "feature = [mapping(geometry)] # can also do this using polygon.__geo_interface__\n",
    "print(type(feature))\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extract the raster values values within the polygon using the rasterio [mask() function](https://rasterio.readthedocs.io/en/latest/api/rasterio.mask.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_image, out_transform = mask(full_dataset, feature, crop=True)\n",
    "out_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay those looks like the right dimensions for our training data. 8 bands and 6x8 pixels seems reasonable given our earlier explorations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be doing a lot of memory intensive work so let's clean up and close this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Training Data for `scikit-learn`\n",
    "\n",
    "Now let's do it for all features in the shapefile and create an array `X` that has all the pixels and an array `y` that has all the training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([], dtype=np.int8).reshape(0,8) # pixels for training\n",
    "y = np.array([], dtype=np.string_) # labels for training\n",
    "\n",
    "# extract the raster values within the polygon \n",
    "with rasterio.open(img_fp) as src:\n",
    "    band_count = src.count\n",
    "    for index, geom in enumerate(geoms):\n",
    "        feature = [mapping(geom)]\n",
    "\n",
    "        # the mask function returns an array of the raster pixels within this feature\n",
    "        out_image, out_transform = mask(src, feature, crop=True) \n",
    "        # eliminate all the pixels with 0 values for all 8 bands - AKA not actually part of the shapefile\n",
    "        out_image_trimmed = out_image[:,~np.all(out_image == 0, axis=0)]\n",
    "        # eliminate all the pixels with 255 values for all 8 bands - AKA not actually part of the shapefile\n",
    "        out_image_trimmed = out_image_trimmed[:,~np.all(out_image_trimmed == 255, axis=0)]\n",
    "        # reshape the array to [pixel count, bands]\n",
    "\n",
    "        # append the labels to the y array\n",
    "        y = np.append(y,[shapefile[\"Classname\"][index]] * out_image_reshaped.shape[0]) \n",
    "        # stack the pizels onto the pixel array\n",
    "        X = np.vstack((X,out_image_reshaped))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairing Y with X\n",
    "Now that we have the image we want to classify (our X feature inputs), and the land cover labels (our y labeled data), let's check to make sure they match in size so we can feed them to Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are our classification labels?\n",
    "labels = np.unique(shapefile[\"Classname\"])\n",
    "print('The training data include {n} classes: {classes}\\n'.format(n=labels.size, \n",
    "                                                                classes=labels))\n",
    "\n",
    "# We will need a \"X\" matrix containing our features, and a \"y\" array containing our labels\n",
    "print('Our X matrix is sized: {sz}'.format(sz=X.shape))\n",
    "print('Our y array is sized: {sz}'.format(sz=y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It all looks good! Let's explore the spectral signatures of each class now to make sure they're actually separable since all we're going by in this classification is pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3, figsize=[20,8])\n",
    "\n",
    "# numbers 1-8\n",
    "band_count = np.arange(1,9)\n",
    "\n",
    "classes = np.unique(y)\n",
    "for class_type in classes:\n",
    "    band_intensity = np.mean(X[y==class_type, :], axis=0)\n",
    "    ax[0].plot(band_count, band_intensity, label=class_type)\n",
    "    ax[1].plot(band_count, band_intensity, label=class_type)\n",
    "    ax[2].plot(band_count, band_intensity, label=class_type)\n",
    "# plot them as lines\n",
    "\n",
    "# Add some axis labels\n",
    "ax[0].set_xlabel('Band #')\n",
    "ax[0].set_ylabel('Reflectance Value')\n",
    "ax[1].set_ylabel('Reflectance Value')\n",
    "ax[1].set_xlabel('Band #')\n",
    "ax[2].set_ylabel('Reflectance Value')\n",
    "ax[2].set_xlabel('Band #')\n",
    "#ax[0].set_ylim(32,38)\n",
    "ax[1].set_ylim(32,38)\n",
    "ax[2].set_ylim(70,140)\n",
    "#ax.set\n",
    "ax[1].legend(loc=\"upper right\")\n",
    "# Add a title\n",
    "ax[0].set_title('Band Intensities Full Overview')\n",
    "ax[1].set_title('Band Intensities Lower Ref Subset')\n",
    "ax[2].set_title('Band Intensities Higher Ref Subset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look okay but emergent wetland and water look quite similar! They're going to be difficult to differentiate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a quick helper function, this one will convert the class labels into indicies and then assign a dictionary relating the class indices and their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_class_to_int(class_array):\n",
    "    class_array[class_array == 'Subtidal Haline'] = 0\n",
    "    class_array[class_array == 'WetSand'] = 1\n",
    "    class_array[class_array == 'Emergent Wetland'] = 2\n",
    "    class_array[class_array == 'Sand'] = 3\n",
    "    class_array[class_array == 'Herbaceous'] = 4\n",
    "    class_array[class_array == 'Forested Wetland'] = 5\n",
    "    return(class_array.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the Classifier**\n",
    "Now that we have our X matrix of feature inputs (the spectral bands) and our y array (the labels), we can train our model.\n",
    "# Quiz 1\n",
    "ให้ลองเปลี่ยน Classifier สามารถดูรายละเอียดได้ที่ https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "gnb = KNeighborsClassifier()\n",
    "gnb.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is that simple to train a classifier in `scikit-learn`! The hard part is often validation and interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.plot import show\n",
    "from rasterio.plot import show_hist\n",
    "from rasterio.windows import Window\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(img_fp) as src:\n",
    "    # may need to reduce this image size if your kernel crashes, takes a lot of memory\n",
    "    img = src.read()[:, 150:600, 250:1400]\n",
    "\n",
    "# Take our full image and reshape into long 2d array (nrow * ncol, nband) for classification\n",
    "print(img.shape)\n",
    "reshaped_img = reshape_as_image(img)\n",
    "print(reshaped_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict for each pixel in our image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prediction = gnb.predict(reshaped_img.reshape(-1, 8))\n",
    "\n",
    "# Reshape our classification map back into a 2D matrix so we can visualize it\n",
    "class_prediction = class_prediction.reshape(reshaped_img[:, :, 0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our shapefile came with the labels as strings we want to convert them to a numpy array with ints using the helper function we made earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_prediction = str_class_to_int(class_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize it!\n",
    "\n",
    "First we'll make a colormap so we can visualize the classes, which are just encoded as integers, in more logical colors. Don't worry too much if this code is confusing! It can be a little clunky to specify colormaps for `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_stretch(image, index):\n",
    "    colors = image[:, :, index].astype(np.float64)\n",
    "    for b in range(colors.shape[2]):\n",
    "        colors[:, :, b] = rasterio.plot.adjust_band(colors[:, :, b])\n",
    "    return colors\n",
    "    \n",
    "# find the highest pixel value in the prediction image\n",
    "n = int(np.max(class_prediction))\n",
    "\n",
    "# next setup a colormap for our map\n",
    "colors = dict((\n",
    "    (0, (48, 156, 214, 255)),   # Blue - Water\n",
    "    (1, (139,69,19, 255)),      # Brown - WetSand\n",
    "    (2, (96, 19, 134, 255)),    # Purple - Emergent Wetland\n",
    "    (3, (244, 164, 96, 255)),   # Tan - Sand\n",
    "    (4, (206, 224, 196, 255)),  # Lime - Herbaceous\n",
    "    (5, (34, 139, 34, 255)),    # Forest Green - Forest \n",
    "))\n",
    "\n",
    "# Put 0 - 255 as float 0 - 1\n",
    "for k in colors:\n",
    "    v = colors[k]\n",
    "    _v = [_v / 255.0 for _v in v]\n",
    "    colors[k] = _v\n",
    "    \n",
    "index_colors = [colors[key] if key in colors else \n",
    "                (255, 255, 255, 0) for key in range(0, n+1)]\n",
    "\n",
    "cmap = plt.matplotlib.colors.ListedColormap(index_colors, 'Classification', n+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now show the classified map next to the RGB image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,1,figsize=(10,7))\n",
    "\n",
    "img_stretched = color_stretch(reshaped_img, [4, 3, 2])\n",
    "axs[0].imshow(img_stretched)\n",
    "\n",
    "axs[1].imshow(class_prediction, cmap=cmap, interpolation='none')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This looks pretty good!\n",
    "\n",
    "Let's generate a map of Normalized Difference Water Index (NDWI) and NDVI just to compare with out output map.\n",
    "\n",
    "NDWI is similar to NDVI but for identifying water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(img_fp) as src:\n",
    "    green_band = src.read(3)\n",
    "    red_band = src.read(4)\n",
    "    nir_band = src.read(8)\n",
    "    \n",
    "ndwi = (green_band.astype(float) - nir_band.astype(float)) / (green_band.astype(float) + nir_band.astype(float))\n",
    "ndvi = (nir_band.astype(float) - red_band.astype(float)) / (red_band.astype(float) + nir_band.astype(float))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset them to our area of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwi = ndwi[150:600, 250:1400]\n",
    "ndvi = ndvi[150:600, 250:1400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display all four maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(15,7))\n",
    "\n",
    "img_stretched = color_stretch(reshaped_img, [3, 2, 1])\n",
    "axs[0,0].imshow(img_stretched)\n",
    "\n",
    "axs[0,1].imshow(class_prediction, cmap=cmap, interpolation='none')\n",
    "\n",
    "nwdi_plot = axs[1,0].imshow(ndwi, cmap=\"RdYlGn\")\n",
    "axs[1,0].set_title(\"NDWI\")\n",
    "fig.colorbar(nwdi_plot, ax=axs[1,0])\n",
    "\n",
    "ndvi_plot = axs[1,1].imshow(ndvi, cmap=\"RdYlGn\")\n",
    "axs[1,1].set_title(\"NDVI\")\n",
    "fig.colorbar(ndvi_plot, ax=axs[1,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good! Areas that are high on the NDWI ratio are generally classified as water and areas high on NDVI are forest and herbaceous. It does seem like the wetland areas (e.g. the bottom right island complex) aren't being picked up so it might be worth experimenting with other algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the Duke Marine Lab and the tip of the Rachel Carson Reserve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(15,15))\n",
    "\n",
    "img_stretched = color_stretch(reshaped_img, [3, 2, 1])\n",
    "axs[0].imshow(img_stretched[0:180, 160:350])\n",
    "\n",
    "axs[1].imshow(class_prediction[0:180, 160:350], cmap=cmap, interpolation='none')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually doesn't look half bad! Land cover mapping is a complex problem and one where there are many approaches and tools for improving a map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing an Unsupervised Classification Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also try a unsupervised classification algorithm, k-means clustering, in the scikit-learn library ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html))\n",
    "\n",
    "K-means ([wikipedia page](https://en.wikipedia.org/wiki/K-means_clustering)) aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 2\n",
    "ลองเปลี่ยนจำนวน Class ในการประมวลผล K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "bands, rows, cols = img.shape\n",
    "\n",
    "k = 10 # num of clusters\n",
    "\n",
    "kmeans_predictions = KMeans(n_clusters=k, random_state=0).fit(reshaped_img.reshape(-1, 8))\n",
    "\n",
    "kmeans_predictions_2d = kmeans_predictions.labels_.reshape(rows, cols)\n",
    "\n",
    "# Now show the classmap next to the image\n",
    "fig, axs = plt.subplots(1,2,figsize=(15,8))\n",
    "\n",
    "img_stretched = color_stretch(reshaped_img, [3, 2, 1])\n",
    "axs[0].imshow(img_stretched)\n",
    "\n",
    "axs[1].imshow(kmeans_predictions_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(15,15))\n",
    "\n",
    "img_stretched = color_stretch(reshaped_img, [3, 2, 1])\n",
    "axs[0].imshow(img_stretched[0:180, 160:350])\n",
    "\n",
    "axs[1].imshow(kmeans_predictions_2d[0:180, 160:350], cmap=cmap, interpolation='none')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}