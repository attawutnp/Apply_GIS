{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPGs4XnJ70g3"
   },
   "source": [
    "87613259\tScripting Language\n",
    "=======================================\n",
    "Credit : Patrick Gray (patrick.c.gray at duke) - https://github.com/patrickcgray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWeDk5Jm7tyQ"
   },
   "source": [
    "### Create all the Utility Functions We'll Need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDkwkC9sCacs"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "from rasterio.plot import adjust_band\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "from rasterio.plot import show\n",
    "from rasterio.windows import Window\n",
    "import rasterio.features\n",
    "import rasterio.warp\n",
    "import rasterio.mask\n",
    "\n",
    "from pyproj import Proj, transform\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def gen_balanced_pixel_locations(image_datasets, train_count, label_dataset, merge=False):\n",
    "    ### this function pulls out a train_count + val_count number of random pixels from a list of raster datasets\n",
    "    ### and returns a list of training pixel locations and image indices \n",
    "    ### and a list of validation pixel locations and indices\n",
    "    \n",
    "    label_proj = Proj(label_dataset.crs)    \n",
    "    train_pixels = []\n",
    "    \n",
    "    train_count_per_dataset = math.ceil(train_count / len(image_datasets))\n",
    "    for index, image_dataset in enumerate(tqdm(image_datasets)):\n",
    "        # how many points from each class\n",
    "        points_per_class = train_count_per_dataset // len(np.unique(merge_classes(labels_image)))\n",
    "        \n",
    "        # get landsat boundaries in this image\n",
    "        # create approx dataset mask in geographic coords\n",
    "        # this fcn maps pixel locations in (row, col) coordinates to (x, y) spatial positions\n",
    "        raster_points = image_dataset.transform * (0, 0), image_dataset.transform * (image_dataset.width, 0), image_dataset.transform * (image_dataset.width, image_dataset.height), image_dataset.transform * (0, image_dataset.height)\n",
    "        l8_proj = Proj(image_dataset.crs)\n",
    "        new_raster_points = []\n",
    "        # convert the raster bounds from landsat into label crs\n",
    "        for x,y in raster_points:\n",
    "            x,y = transform(l8_proj,label_proj,x,y)\n",
    "            # convert from crs into row, col in label image coords\n",
    "            row, col = label_dataset.index(x, y)\n",
    "            # don't forget row, col is actually y, x so need to swap it when we append\n",
    "            new_raster_points.append((col, row))\n",
    "        # turn this into a polygon\n",
    "        raster_poly = Polygon(new_raster_points)\n",
    "        # Window.from_slices((row_start, row_stop), (col_start, col_stop))\n",
    "        masked_label_image = label_dataset.read(window=Window.from_slices((int(raster_poly.bounds[1]), int(raster_poly.bounds[3])), (int(raster_poly.bounds[0]), int(raster_poly.bounds[2]))))\n",
    "        if merge:\n",
    "            masked_label_image = merge_classes(masked_label_image)\n",
    "        # loop for each class\n",
    "        all_points_per_image = []\n",
    "        for cls in np.unique(merge_classes(labels_image)):\n",
    "            cls = int(cls)\n",
    "            # mask the label subset image to each class\n",
    "            # pull out the indicies where the mask is true\n",
    "            rows,cols = np.where(masked_label_image[0] == cls)\n",
    "            all_locations = list(zip(rows,cols))\n",
    "       \n",
    "            # shuffle all locations\n",
    "            random.shuffle(all_locations)\n",
    "            # now convert to landsat image crs\n",
    "            # TODO need to time this to see if it is slow, can probably optimize\n",
    "            l8_points = []\n",
    "            # TODO Will probably need to catch this for classes smaller than the ideal points per class\n",
    "            if len(all_locations)!=0:\n",
    "                for r,c in all_locations[:points_per_class]:\n",
    "                # convert label row and col into label geographic space\n",
    "                    x,y = label_dataset.xy(r+raster_poly.bounds[1],c+raster_poly.bounds[0])\n",
    "                # go from label projection into landsat projection\n",
    "                    x,y = transform(label_proj, l8_proj,x,y)\n",
    "                # convert from landsat geographic space into row col\n",
    "                    r,c = image_dataset.index(x,y)\n",
    "                    l8_points.append((r,c))\n",
    "                all_points_per_image += l8_points\n",
    "\n",
    "        dataset_index_list = [index] * len(all_points_per_image)\n",
    "\n",
    "        dataset_pixels = list(zip(all_points_per_image, dataset_index_list))\n",
    "        train_pixels += dataset_pixels\n",
    "    random.shuffle(train_pixels)\n",
    "    return (train_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nY7L3cXJDRQz"
   },
   "outputs": [],
   "source": [
    "def tile_generator(l8_image_datasets, label_dataset, tile_height, tile_width, pixel_locations, batch_size, merge=False):\n",
    "    ### this is a keras compatible data generator which generates data and labels on the fly \n",
    "    ### from a set of pixel locations, a list of image datasets, and a label dataset\n",
    "     \n",
    "\n",
    "    c = r = 0\n",
    "    i = 0\n",
    "    \n",
    "    label_proj = Proj(label_dataset.crs)\n",
    "\n",
    "    # assuming all images have the same num of bands\n",
    "    l8_band_count = l8_image_datasets[0].count  \n",
    "    band_count = l8_band_count\n",
    "    class_count = len(class_names)\n",
    "    buffer = math.ceil(tile_height / 2)\n",
    "  \n",
    "    while True:\n",
    "        image_batch = np.zeros((batch_size, tile_height, tile_width, band_count-1)) # take one off because we don't want the QA band\n",
    "        label_batch = np.zeros((batch_size,class_count))\n",
    "        b = 0\n",
    "        while b < batch_size:\n",
    "            # if we're at the end  of the data just restart\n",
    "            if i >= len(pixel_locations):\n",
    "                i=0\n",
    "            r, c = pixel_locations[i][0]\n",
    "            dataset_index = pixel_locations[i][1]\n",
    "            i += 1\n",
    "            tile = l8_image_datasets[dataset_index].read(list(np.arange(1, l8_band_count+1)), window=Window(c-buffer, r-buffer, tile_width, tile_height))\n",
    "            if tile.size == 0:\n",
    "                pass\n",
    "            elif np.amax(tile) == 0: # don't include if it is part of the image with no pixels\n",
    "                pass\n",
    "            elif np.isnan(tile).any() == True or -9999 in tile: \n",
    "                # we don't want tiles containing nan or -999 this comes from edges\n",
    "                # this also takes a while and is inefficient\n",
    "                pass\n",
    "            elif tile.shape != (l8_band_count, tile_width, tile_height):\n",
    "                #print('wrong shape')\n",
    "                #print(tile.shape)\n",
    "                # somehow we're randomly getting tiles without the correct dimensions\n",
    "                pass\n",
    "            elif np.isin(tile[7,:,:], [352, 368, 392, 416, 432, 480, 840, 864, 880, 904, 928, 944, 1352]).any() == True:\n",
    "                # make sure pixel doesn't contain clouds\n",
    "                # this is probably pretty inefficient but only checking width x height for each tile\n",
    "                # read more here: https://prd-wret.s3-us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/atoms/files/LSDS-1873_US_Landsat_ARD_DFCB_0.pdf\n",
    "                #print('Found some cloud.')\n",
    "                #print(tile[7,:,:])\n",
    "                pass\n",
    "            else:                \n",
    "                # taking off the QA band\n",
    "                tile = tile[0:7]\n",
    "                # reshape from raster format to image format and standardize according to image wide stats\n",
    "                reshaped_tile = (reshape_as_image(tile)  - 982.5) / 1076.5\n",
    "\n",
    "                ### get label data\n",
    "                # find gps of that pixel within the image\n",
    "                (x, y) = l8_image_datasets[dataset_index].xy(r, c)\n",
    "\n",
    "                # convert the point we're sampling from to the same projection as the label dataset if necessary\n",
    "                if l8_proj != label_proj:\n",
    "                    x,y = transform(l8_proj,label_proj,x,y)\n",
    "\n",
    "                # reference gps in label_image\n",
    "                row, col = label_dataset.index(x,y)\n",
    "\n",
    "                # find label\n",
    "                # label image could be huge so we need this to just get a single position\n",
    "                window = ((row, row+1), (col, col+1))\n",
    "                data = merge_classes(label_dataset.read(1, window=window, masked=False, boundless=True))\n",
    "                label = data[0,0]\n",
    "                # if this label is part of the unclassified area then ignore\n",
    "                if label == 0 or np.isnan(label).any() == True:\n",
    "                    pass\n",
    "                else:                   \n",
    "                    # add label to the batch in a one hot encoding style\n",
    "                    label_batch[b][label] = 1\n",
    "                    image_batch[b] = reshaped_tile\n",
    "                    b += 1\n",
    "        yield (image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnqxxgogQCQj"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, class_dict,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    # convert class_id to class_name using the class_dict\n",
    "    cover_names = []\n",
    "    for cover_class in classes:\n",
    "        cover_names.append(class_dict[cover_class])\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    else:\n",
    "        pass\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=cover_names, yticklabels=cover_names,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qi3Wr-e1D9xT"
   },
   "outputs": [],
   "source": [
    "def merge_classes(y):\n",
    "    # reclassify 255 to 0\n",
    "    y[y == 255] = 0\n",
    "    # medium intensity and high intensity\n",
    "    y[y == 3] = 2\n",
    "    # low intensity and high intensity\n",
    "    y[y == 4] = 2\n",
    "\n",
    "    # open space developed, cultivated land, and pasture hay\n",
    "    y[y == 5] = 6\n",
    "    y[y == 7] = 6\n",
    "\n",
    "    # decidious and mixed\n",
    "    y[y == 9] = 11\n",
    "    # evergreen to mixed\n",
    "    y[y == 10] = 11\n",
    "    # shrub and mixed\n",
    "    y[y == 12] = 11\n",
    "    # wetland forest to mixed\n",
    "    y[y == 13] = 11\n",
    "    # pal wetland and pal scrub shrub\n",
    "    y[y == 14] = 18\n",
    "    y[y == 15] = 18\n",
    "    y[y == 16] = 18\n",
    "    y[y == 17] = 18\n",
    "    \n",
    "    # pal bed to water\n",
    "    y[y == 22] = 21\n",
    "    # unconsol shore to water\n",
    "    y[y == 19] = 21\n",
    "    \n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ng4KwzvDsmq"
   },
   "outputs": [],
   "source": [
    "class_names = dict((\n",
    "(0,  'Background'),\n",
    "(1, 'Unclassified'),\n",
    "(2, 'High Intensity Developed'),\n",
    "(3, 'Medium Intensity Developed'),\n",
    "(4, 'Low Intensity Developed'),\n",
    "(5, 'Open Space Developed'),\n",
    "(6, 'Cultivated Land'),\n",
    "(7, 'Pasture/Hay'),\n",
    "(8, 'Grassland'),\n",
    "(9, 'Deciduous Forest'),\n",
    "(10, 'Evergreen Forest'),\n",
    "(11, 'Mixed Forest'),\n",
    "(12, 'Scrub/Shrub'),\n",
    "(13, 'Palustrine Forested Wetland'),\n",
    "(14, 'Palustrine Scrub/Shrub Wetland'),\n",
    "(15, 'Palustrine Emergent Wetland'),\n",
    "(16, 'Estuarine Forested Wetland'),\n",
    "(17, 'Estuarine Scrub/Shrub Wetland'),\n",
    "(18, 'Estuarine Emergent Wetland'),\n",
    "(19, 'Unconsolidated Shore'),\n",
    "(20, 'Bare Land'),\n",
    "(21, 'Water'),\n",
    "(22, 'Palustrine Aquatic Bed'),\n",
    "(23, 'Estuarine Aquatic Bed'),\n",
    "(24, 'Tundra'),\n",
    "(25, 'Snow/Ice')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "Pt_q6_SQ48wZ",
    "outputId": "c0358ca3-e3aa-48ab-c994-a8bdf4393dfc"
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Open our raster dataset\n",
    "landsat_dataset = rasterio.open('landsat_image.tif')\n",
    "\n",
    "# How many bands does this image have?\n",
    "num_bands = landsat_dataset.count\n",
    "print('Number of bands in image: {n}\\n'.format(n=num_bands))\n",
    "\n",
    "# How many rows and columns?\n",
    "rows, cols = landsat_dataset.shape\n",
    "print('Image size is: {r} rows x {c} columns\\n'.format(r=rows, c=cols))\n",
    "\n",
    "# What driver was used to open the raster?\n",
    "driver = landsat_dataset.driver\n",
    "print('Raster driver: {d}\\n'.format(d=driver))\n",
    "\n",
    "# What is the raster's projection?\n",
    "proj = landsat_dataset.crs\n",
    "print('Image projection:')\n",
    "print(proj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQOn2wwF96-5"
   },
   "source": [
    "Open up the dataset and read it into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mBgu28Kj7WHw",
    "outputId": "92689686-d09d-4345-fb40-2e8f58e8a54a"
   },
   "outputs": [],
   "source": [
    "landsat_image = landsat_dataset.read()\n",
    "landsat_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JsFccm-9-ACt"
   },
   "source": [
    "Let's calculate NDVI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jE4HiOkb7Py4"
   },
   "outputs": [],
   "source": [
    "bandNIR = landsat_image[4, :, :]\n",
    "bandRed = landsat_image[3, :, :]\n",
    "\n",
    "ndvi = np.clip((bandNIR.astype(float) - bandRed.astype(float)) / (bandNIR.astype(float) + bandRed.astype(float)), -1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "-dyg1pGY7Sjx",
    "outputId": "3219d9e3-5908-4408-96fe-bb7080abb7b1"
   },
   "outputs": [],
   "source": [
    "print('\\nMax NDVI: {m}'.format(m=ndvi.max()))\n",
    "print('Mean NDVI: {m}'.format(m=ndvi.mean()))\n",
    "print('Median NDVI: {m}'.format(m=np.median(ndvi)))\n",
    "print('Min NDVI: {m}'.format(m=ndvi.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "QhjFb8M_8HJ4",
    "outputId": "e15f2561-a872-4ea4-bd5b-5723464f59d6"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "\n",
    "# We can set the number of bins with the `bins` kwarg\n",
    "axs.hist(ndvi.flatten(), bins=50)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJIgZNds-PP2"
   },
   "source": [
    "NDVI looks normal, let's check out the whole image histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "H-nqFDHh6OtK",
    "outputId": "0e52a4f1-1540-4fa4-e7b2-453cd696ee74"
   },
   "outputs": [],
   "source": [
    "rasterio.plot.show_hist(landsat_dataset.read([1,2,3,4,5,6,7]), bins=50, histtype='stepfilled', lw=0.0, stacked=False, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2gE319v-EVj"
   },
   "source": [
    "Now we'll visualize the landsat image and NDVI side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913
    },
    "colab_type": "code",
    "id": "odb65Zhy5FRB",
    "outputId": "27fe32b2-d0ee-45da-f8bb-250c994eb39c"
   },
   "outputs": [],
   "source": [
    "from rasterio.plot import adjust_band\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "from rasterio.plot import show\n",
    "\n",
    "# pull out the bands we want to visualize\n",
    "index = np.array([3, 2, 1])\n",
    "colors = landsat_image[index, :, :].astype(np.float64)\n",
    "\n",
    "# we'll use the values to stretch the landsat image based on the above histogram\n",
    "max_val = 2500\n",
    "min_val = 0\n",
    "\n",
    "# enforce maximum and minimum values\n",
    "colors[colors[:, :, :] > max_val] = max_val\n",
    "colors[colors[:, :, :] < min_val] = min_val\n",
    "\n",
    "for b in range(colors.shape[0]):\n",
    "    colors[b, :, :] = colors[b, :, :] * 1 / (max_val - min_val)\n",
    "\n",
    "# rasters are in the format [bands, rows, cols] whereas images are typically [rows, cols, bands]\n",
    "# and so our array needs to be reshaped\n",
    "print(colors.shape)\n",
    "colors_reshaped = reshape_as_image(colors)\n",
    "print(colors_reshaped.shape)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 15)) \n",
    "\n",
    "# Show the color image\n",
    "axs[0].imshow(colors_reshaped)\n",
    "axs[0].set_title('Color Image')\n",
    "\n",
    "# Show NDVI\n",
    "axs[1].imshow(ndvi, cmap='RdYlGn')\n",
    "axs[1].set_title('NDVI')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k8Dc6J-oF0Gl"
   },
   "source": [
    "Now let's check out the quality band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "ncDeE9FZiS_d",
    "outputId": "2f3ce14c-6df5-423f-b7ac-9a44741bc685"
   },
   "outputs": [],
   "source": [
    "qa_band = landsat_image[2, :, :]\n",
    "qa_band[qa_band == -9999] = 0\n",
    "\n",
    "print(np.unique(qa_band))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ax.imshow(qa_band, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOTMZxNz7Vx3"
   },
   "source": [
    "Read in the training labels image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LVou6etFAgr8",
    "outputId": "410085c9-f483-40ed-e6b0-16e33784ca0d"
   },
   "outputs": [],
   "source": [
    "labels_dataset = rasterio.open('labels_image.tif')\n",
    "# we're merging here just to limit the number of classes we're working with\n",
    "labels_image = merge_classes(labels_dataset.read())\n",
    "labels_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xE-bM05N-m66"
   },
   "source": [
    "How many pixels are there of each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "2unJDbI-BKyd",
    "outputId": "35fcc374-d961-4d28-fe10-f07c74cb4d51"
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(labels_image, return_counts=True)\n",
    "list(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFzFFXeItF_f"
   },
   "source": [
    "Let's view the training labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "8EluaG1DBCdO",
    "outputId": "73865e6c-c3ce-4f63-d414-b9d6b281daaf"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# we then use these objects to draw-on and manipulate our plot\n",
    "ax.imshow(labels_image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkCWveqRtIK_"
   },
   "source": [
    "Now with a more logical color map:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "vKiOSL_bBgsV",
    "outputId": "eee74916-46fc-4341-b04e-496cb08beeb8"
   },
   "outputs": [],
   "source": [
    "# next setup a colormap for our map\n",
    "colors = dict((\n",
    "(0, (245,245,245, 255)), # Background\n",
    "(1, (0,0,0)), # Unclassified (Cloud, Shadow, etc)\n",
    "(2, (255,0,0)), # High Intensity Developed\n",
    "(3, (255, 110, 51)), # Medium Intensity Developed\n",
    "(4, (255, 162, 51)), # Low Intensity Developed\n",
    "(5, (255, 162, 51)), # Open Space Developed\n",
    "(6, (162, 89, 0)), # Cultivated Land\n",
    "(7, (229, 221, 50)), # Pasture/Hay\n",
    "(8, (185, 251, 96)), # Grassland\n",
    "(9, (83, 144, 0)), # Deciduous Forest\n",
    "(10, (13, 118, 0  )), # Evergreen Forest\n",
    "(11, (62, 178, 49)), # Mixed Forest\n",
    "(12, (100, 241, 125)), # Scrub/Shrub\n",
    "(13, (68, 160, 85)), # Palustrine Forested Wetland\n",
    "(14, (118, 192, 131)), # Palustrine Scrub/Shrub Wetland\n",
    "(15, (188, 0, 211)), # Palustrine Emergent Wetland\n",
    "(16, (188, 0, 211)), # Estuarine Forested Wetland\n",
    "(17, (0, 0, 0)), # Estuarine Scrub/Shrub Wetland\n",
    "(18, (172, 0, 191)), # Estuarine Emergent Wetland\n",
    "(19, (159, 251, 255)), # Unconsolidated Shore \n",
    "(20, (172, 177, 68)), # Bare Land\n",
    "(21, (29, 0, 189)), # Water\n",
    "(22, (40, 40, 40)), # Pal Bed\n",
    "))\n",
    "\n",
    "n = int(np.max(labels_image)) + 1\n",
    "\n",
    "\n",
    "# Put 0 - 255 as float 0 - 1\n",
    "for k in colors:\n",
    "    v = colors[k]\n",
    "    _v = [_v / 255.0 for _v in v]\n",
    "    colors[k] = _v\n",
    "    \n",
    "index_colors = [colors[key] for key in range(0, n)]\n",
    "\n",
    "cmap = plt.matplotlib.colors.ListedColormap(index_colors, 'Classification', n)\n",
    "\n",
    "# Now show the class map next to the RGB image\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(10,10))\n",
    "\n",
    "axs.imshow(labels_image[0,:, :], cmap=cmap, interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yrmwa4ugtMkr"
   },
   "source": [
    "Generate a set of random class balanced pixel locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VtW4SB6gFGox",
    "outputId": "291d925d-4337-458e-ea88-073ef4f96f49"
   },
   "outputs": [],
   "source": [
    "train_pixels = gen_balanced_pixel_locations([landsat_dataset], train_count=100, \n",
    "                                            label_dataset=labels_dataset, merge=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code takes a while to run and isn't necessary to run the CNN, But it is good practice to ensure you have a balanced and correct dataset. It also is a nice sanity check to map out the actual location of the pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kzPe0r-_F4Zy",
    "outputId": "39eb7b47-0df7-4b07-b3fb-6ec30f41f187"
   },
   "outputs": [],
   "source": [
    "landsat_datasets = [landsat_dataset]\n",
    "# generate the training and validation pixel locations\n",
    "all_labels = []\n",
    "label_locations = []\n",
    "for pixel in train_pixels:\n",
    "    # row, col location in landsat\n",
    "    r,c = pixel[0]\n",
    "    ds_index = pixel[1]\n",
    "    l8_proj = Proj(landsat_datasets[ds_index].crs)\n",
    "    label_proj = Proj(labels_dataset.crs)\n",
    "    \n",
    "    # geographic location in landsat\n",
    "    x,y = landsat_datasets[ds_index].xy(r,c)\n",
    "    # go from label projection into landsat projection\n",
    "    x,y = transform(l8_proj, label_proj ,x,y)\n",
    "    # get row and col location in label\n",
    "    r,c = labels_dataset.index(x,y)\n",
    "    \n",
    "    label_locations.append([r,c])\n",
    "    \n",
    "    # format (bands, height, width)\n",
    "    window = ((r, r+1), (c, c+1))\n",
    "    data = merge_classes(labels_dataset.read(1, window=window, masked=False, boundless=True))\n",
    "    all_labels.append(data[0,0])\n",
    "    \n",
    "label_locations = np.array(label_locations)\n",
    "\n",
    "unique, counts = np.unique(np.array(all_labels), return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9krQTTu-tkwU"
   },
   "source": [
    "#### Test out the generator:\n",
    "\n",
    "Print out some image and label batches and check out their shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "yCXTnWK8J8LE",
    "outputId": "2914e89e-9770-46d1-bbbf-caa93e53d320"
   },
   "outputs": [],
   "source": [
    "im_batch = None\n",
    "\n",
    "count = 0\n",
    "for (im, label) in tile_generator(landsat_datasets, labels_dataset, 128, 128, train_pixels, 10):\n",
    "    if count > 3:\n",
    "        break\n",
    "    print('Image')\n",
    "    print(im.shape)\n",
    "    print('Label')\n",
    "    print(label.shape)\n",
    "    print('----')\n",
    "    count += 1\n",
    "    im_batch = im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VMWZ9hMuIBO"
   },
   "source": [
    "### Explore the data:\n",
    "\n",
    "#### Generate training dataset of 1x1 tiles for scikit-learn to visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "BxVPxQPW6yks",
    "outputId": "1dafd52a-31d3-4ff7-ffc2-ee9fe988db7a"
   },
   "outputs": [],
   "source": [
    "im_batch = None\n",
    "label_batch = None\n",
    "\n",
    "sample_size = 500\n",
    "\n",
    "count = 0\n",
    "for (im, label) in tile_generator(landsat_datasets, labels_dataset, 1, 1, train_pixels, sample_size):\n",
    "    if count > 0:\n",
    "        break\n",
    "    print('Batch Shape')\n",
    "    print(im.shape)\n",
    "    print('Label Shape')\n",
    "    print(label.shape)\n",
    "    print('----')\n",
    "    count += 1\n",
    "    im_batch = im\n",
    "    label_batch = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ZJKYR_DTcCU"
   },
   "source": [
    "Reshape because scikit-learn needs daya in `(samples, bands)` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vZqFVntt7k2y",
    "outputId": "b743cb82-38db-4f5f-be74-5d86e81dec28"
   },
   "outputs": [],
   "source": [
    "im_batch[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IUhfVaq28Xfi",
    "outputId": "2aaee9b5-50bb-40d0-e803-e6b431f6b014"
   },
   "outputs": [],
   "source": [
    "im_batch_reshaped = im_batch.reshape(sample_size,7)\n",
    "im_batch_reshaped[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNs6MwKz-myd"
   },
   "source": [
    "#### Visualize Spectral Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "QgYCvsiA8NFd",
    "outputId": "edd31477-238a-464f-bd8f-8cfe04485658"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=[10,10])\n",
    "\n",
    "# numbers 1-8\n",
    "band_count = np.arange(1,8)\n",
    "\n",
    "y = np.argmax(label_batch, axis=1)\n",
    "X = im_batch_reshaped\n",
    "\n",
    "classes = np.unique(y)\n",
    "for class_type in classes:\n",
    "    band_intensity = np.mean(X[y==class_type, :], axis=0)\n",
    "    ax.plot(band_count, band_intensity, label=class_names[class_type])\n",
    "# plot them as lines\n",
    "\n",
    "# Add some axis labels\n",
    "ax.set_xlabel('Band #')\n",
    "ax.set_ylabel('Reflectance Value')\n",
    "# Add a title\n",
    "ax.set_title('Band Intensities Full Overview')\n",
    "ax.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aueH7uu2-qYW"
   },
   "source": [
    "#### Run Principle Components Analysis to visualize points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6LIcMi5a9LWb",
    "outputId": "c9d092df-2a11-410a-db34-fea2a093618b"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(im_batch_reshaped)\n",
    "\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "df = pd.DataFrame({'pca-one':pca_result[:,0],'pca-two':pca_result[:,1],'pca-three':pca_result[:,2], 'y' : np.argmax(label_batch, axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "M61Z-XHK9X50",
    "outputId": "80ee3997-9088-44cc-c684-dde643e10669"
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(16,10)).gca(projection='3d')\n",
    "ax.scatter(\n",
    "    xs=df[\"pca-one\"], \n",
    "    ys=df[\"pca-two\"], \n",
    "    zs=df[\"pca-three\"], \n",
    "    c=df[\"y\"], \n",
    "    cmap='tab10'\n",
    ")\n",
    "ax.set_xlabel('pca-one')\n",
    "ax.set_ylabel('pca-two')\n",
    "ax.set_zlabel('pca-three')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VB3UUXy8-4Si"
   },
   "source": [
    "#### Run T-distributed Stochastic Neighbor Embedding (t-SNE) to visualize points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "C2glweLV9eI0",
    "outputId": "93551b85-dd0d-4325-d223-b55752a295d4"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "time_start = time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=100, n_iter=1000)\n",
    "tsne_results = tsne.fit_transform(im_batch_reshaped)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6wpdh4OA9wcM"
   },
   "outputs": [],
   "source": [
    "df_subset = df.copy()\n",
    "df_subset['tsne-2d-one'] = tsne_results[:,0]\n",
    "df_subset['tsne-2d-two'] = tsne_results[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "colab_type": "code",
    "id": "4KUcGRx593i8",
    "outputId": "c8942d30-c9a7-4ceb-efb4-076c8cdd7ba7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", len(np.unique(np.argmax(label_batch, axis=1)))),\n",
    "    data=df_subset,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yFyPPa6K_VmH"
   },
   "source": [
    "#### Generate training dataset of 1x1 tiles for scikit-learn to use in Random Forest and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "hNfWrnY9_DXe",
    "outputId": "b492a126-aab3-4c16-8c5f-e6fe080b1849"
   },
   "outputs": [],
   "source": [
    "im_batch = None\n",
    "label_batch = None\n",
    "\n",
    "sample_size = 2000\n",
    "train_count = 1500\n",
    "val_count = 500\n",
    "\n",
    "count = 0\n",
    "for (im, label) in tile_generator(landsat_datasets, labels_dataset, 1, 1, train_pixels, sample_size):\n",
    "    if count > 0:\n",
    "        break\n",
    "    print('Batch Shape')\n",
    "    print(im.shape)\n",
    "    print('Label Shape')\n",
    "    print(label.shape)\n",
    "    print('----')\n",
    "    count += 1\n",
    "    im_batch = im\n",
    "    label_batch = label\n",
    "\n",
    "im_batch_reshaped = im_batch.reshape(sample_size,7)\n",
    "\n",
    "X_train = im_batch_reshaped[:train_count]\n",
    "X_val = im_batch_reshaped[train_count:]\n",
    "y_train = np.argmax(label_batch, axis=1)[:train_count]\n",
    "y_val = np.argmax(label_batch, axis=1)[train_count:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DdRkZ7QDtrTF"
   },
   "source": [
    "### Building the actual neural network model\n",
    "\n",
    "Import all the necessary `keras` packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bgPrE7nfKgBK",
    "outputId": "3e32d026-1bfa-4479-e00c-d5b6f0e7abb0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CSQtcDutv5R"
   },
   "source": [
    "Set the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "so-MzsE6K9wY",
    "outputId": "ba8d927b-4b0d-42ed-b493-18595f7ddc15"
   },
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "epochs = 50\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# input image dimensions\n",
    "tile_side = 32\n",
    "img_rows, img_cols = tile_side, tile_side\n",
    "img_bands = landsat_datasets[0].count- 1\n",
    "\n",
    "input_shape = (img_rows, img_cols, img_bands)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "otFus3i5txy6"
   },
   "source": [
    "#### Create the CNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1516
    },
    "colab_type": "code",
    "id": "Ku9yk42NKq4g",
    "outputId": "1e23e970-67a3-4902-d63b-be8711334e8f"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(num_classes))\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7MkRMH9t0Em"
   },
   "source": [
    "Divide data into training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iSvnToUNLQj4",
    "outputId": "f56319e2-5964-4b52-958e-73d3821a3fa6"
   },
   "outputs": [],
   "source": [
    "train_to_val_ratio = 0.8\n",
    "train_px = train_pixels[:int(len(train_pixels)*train_to_val_ratio)]\n",
    "val_px = train_pixels[int(len(train_pixels)*train_to_val_ratio):]\n",
    "print(\"Train:\", len(train_px), \"\\nVal:\", len(val_px))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DkvcOnqLt2cz"
   },
   "source": [
    "Decide on the optimizier and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "SLAmHQJXLXBo",
    "outputId": "b543577c-dee3-4077-9c5b-5668234f8376"
   },
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "metrics=['accuracy']\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faJAqfMFt-To"
   },
   "source": [
    "### Learn the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YzoQHwnTCTx8"
   },
   "source": [
    "<img src=\"https://i.imgur.com/vFCeROF.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Image from the excellent *Deep Learning with Python* by François Chollet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1160
    },
    "colab_type": "code",
    "id": "HU8eVd2rLciQ",
    "outputId": "34e889cc-e2aa-46d5-cf8e-b880460cf013"
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=tile_generator(landsat_datasets, labels_dataset, tile_side, tile_side, train_px, batch_size, merge=True), \n",
    "                    steps_per_epoch=len(train_px) // batch_size, epochs=epochs, verbose=1,\n",
    "                    validation_data=tile_generator(landsat_datasets, labels_dataset, tile_side, tile_side, val_px, batch_size, merge=True),\n",
    "                    validation_steps=len(val_px) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fu6PRDDwAOi3"
   },
   "source": [
    "Hopefully we found our way down here:\n",
    "\n",
    "<img src=\"https://science.sciencemag.org/content/sci/360/6388/478/F1.large.jpg\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Image from: http://doi.org/10.1126/science.360.6388.478"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NRTAYA-nuCE4"
   },
   "source": [
    "#### Check out accuracy based on a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(generator=tile_generator(landsat_datasets, labels_dataset, tile_side, tile_side, val_px, batch_size, merge=True), \n",
    "                        steps=len(val_px))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1385
    },
    "colab_type": "code",
    "id": "VR9xuMWgYTO7",
    "outputId": "b439d7ad-dc6f-46c1-a48e-415a85b2bef0"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(generator=tile_generator(landsat_datasets, labels_dataset, tile_side, tile_side, train_px, batch_size, merge=True), \n",
    "                        steps=len(train_px) // batch_size,\n",
    "                         verbose=1)\n",
    "\n",
    "eval_generator = tile_generator(landsat_datasets, labels_dataset, tile_side, tile_side, train_px, batch_size=1, merge=True)\n",
    "\n",
    "labels = np.empty(predictions.shape)\n",
    "count = 0\n",
    "while count < len(labels):\n",
    "    image_b, label_b = next(eval_generator)\n",
    "    labels[count] = label_b\n",
    "    count += 1\n",
    "    \n",
    "label_index = np.argmax(labels, axis=1)     \n",
    "pred_index = np.argmax(predictions, axis=1)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(label_index, pred_index, classes=np.array(list(class_names)),\n",
    "                      class_dict=class_names)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(label_index, pred_index, classes=np.array(list(class_names)),\n",
    "                      class_dict=class_names,\n",
    "                      normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "landcover_analysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
